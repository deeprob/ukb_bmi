{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","import hail as hl\n","import os\n","import time\n","import dxpy\n","import logging\n","import pandas as pd\n","import re\n","\n","\n","# Build spark\n","builder = (\n","    SparkSession\n","    .builder\n","    .enableHiveSupport()\n",")\n","spark = builder.getOrCreate()\n","hl.init(sc=spark.sparkContext)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_rare_variants(mt):\n","    \"\"\"\n","    Returns a matrix table with alt allele frequency < 0.001\n","    \"\"\"\n","    mt = mt.annotate_rows(gt_stats = hl.agg.call_stats(mt.GT, mt.alleles))\n","    mt = mt.filter_rows((mt.gt_stats.AF[1] < 0.001) & (mt.gt_stats.AC[1] > 1))\n","    return mt\n","\n","\n","def add_annotations(mt, vep_file=\"file:///mnt/project/exome_annot/annot_run/vep_config_109_v4.json\"):\n","    \"\"\"\n","    Add vep and dbnsfp annotations\n","    \"\"\"\n","    mt = hl.vep(mt, vep_file) # annot table with vep\n","    db = hl.experimental.DB(region='us', cloud='aws')\n","    mt = db.annotate_rows_db(mt, 'dbNSFP_variants') # add dbNSFP annotations\n","    return mt\n","\n","\n","\n","def get_protein_coding_variants(mt):\n","    \"\"\"\n","    Search for protein coding transcript consequences.\n","    \"\"\"\n","    mt = mt.filter_rows(hl.any(lambda x: x==\"protein_coding\", mt.vep.transcript_consequences.biotype))\n","    return mt\n","\n","\n","def create_deleteriousness_scores(mt):\n","    metrics = [\"SIFT\", \"LRT\", \"FATHMM\", \"PROVEAN\", \"MetaSVM\", \"MetaLR\", \"PrimateAI\", \"DEOGEN2\"] # \n","    # metrics with D as deleterious and others as tolerant\n","    kwd_dict = {f\"{m}_pred\":hl.if_else(hl.any(lambda x: x.contains(\"D\"), mt.dbNSFP_variants[f\"{m}_pred\"]), 1., 0) for m in metrics}\n","    mt = mt.annotate_rows(**kwd_dict)\n","    # MutationAssessor\n","    mt = mt.annotate_rows(MutationAssessor_pred=hl.if_else(hl.any(lambda x: x.contains(\"H\"), mt.dbNSFP_variants[\"MutationAssessor_pred\"]), 1., 0))\n","    metrics = metrics + [\"MutationAssessor\"]\n","    cols2sum = [f\"{m}_pred\" for m in metrics]\n","    mt = mt.annotate_rows(del_score=hl.sum([mt[col] for col in cols2sum]))\n","    return mt\n","\n","\n","def create_vtype_annotations(mt):\n","    lof_mutations = hl.set([\n","        \"transcript_ablation\", \"stop_gained\", \"frameshift_variant\", \"stop_lost\", \"start_lost\"\n","    ])\n","    missense_mutations = hl.set([\"missense_variant\"])\n","    splice_lof_mutations = hl.set([\n","        \"splice_acceptor_variant\", \"splice_donor_variant\"\n","    ])\n","    splice_mutations = hl.set([\"splice_donor_5th_base_variant\", \n","        \"splice_region_variant\", \"splice_donor_region_variant\", \"splice_polypyrimidine_tract_variant\"])\n","\n","    mt = mt.annotate_rows(\n","        lof = hl.len(lof_mutations.intersection(hl.set(hl.flatten(mt.vep.transcript_consequences.consequence_terms)))) != 0,\n","        missense = hl.len(missense_mutations.intersection(hl.set(hl.flatten(mt.vep.transcript_consequences.consequence_terms)))) != 0,\n","        splice_lof = hl.len(splice_lof_mutations.intersection(hl.set(hl.flatten(mt.vep.transcript_consequences.consequence_terms)))) != 0,\n","        splice = hl.len(splice_mutations.intersection(hl.set(hl.flatten(mt.vep.transcript_consequences.consequence_terms)))) != 0,\n","    )\n","    return mt\n","\n","\n","def get_deleterious(mt):\n","    # keep all lof (loftee score maybe?) and deleterious missense variants (filter by deleteriousness score, majority vote is 5/9).\n","    mt = mt.filter_rows((mt.lof==True)|(mt.splice_lof==True)|(mt.missense==True)|(mt.splice==True))\n","    return mt\n","\n","\n","def add_gene_info(mt):\n","    mt =  mt.annotate_rows(gene=mt.vep.transcript_consequences.gene_symbol)\n","    mt = mt.explode_rows(mt.gene)\n","    return mt\n","\n","\n","def keep_relevant_columns(mt):\n","    mt = mt.select_rows(\n","        mt.gene, mt.lof, mt.missense, mt.splice_lof, mt.splice, mt.del_score,\n","    )\n","    return mt\n","\n","\n","def get_annot_table(mt):\n","    # split multi-allelic hits to bi-allelic\n","    mt_filtered = hl.split_multi_hts(mt, permit_shuffle=True)\n","    # filter for rare variants only\n","    mt_filtered = get_rare_variants(mt_filtered)\n","    # add vep and dbnsfp annotations\n","    mt_filtered = add_annotations(mt_filtered)\n","    # Only keep protein coding variants\n","    mt_filtered = get_protein_coding_variants(mt_filtered)\n","    # create deleteriousness scores for all variants\n","    mt_filtered = create_deleteriousness_scores(mt_filtered)\n","    # create vtype annotations\n","    mt_filtered = create_vtype_annotations(mt_filtered)\n","    # filter for lof variants or variants above deletrious score threshold\n","    mt_filtered = get_deleterious(mt_filtered)\n","    # add gene info and explode by gene\n","    mt_filtered = add_gene_info(mt_filtered)\n","    # only keep important columns\n","    mt_filtered = keep_relevant_columns(mt_filtered)\n","    # add sample info per variant\n","    mt_filtered = mt_filtered.annotate_rows(samples = hl.bind(lambda x: hl.delimit(x, \",\"), hl.agg.filter(mt_filtered.GT.n_alt_alleles() > 0, hl.agg.collect(mt_filtered.s))))\n","    # get burden table\n","    annot_table = mt_filtered.rows()\n","    annot_df = annot_table.to_pandas()\n","    annot_df[\"alleles\"] = annot_df.alleles.apply(lambda x: \"_\".join(x))\n","    annot_df = annot_df.drop_duplicates().reset_index(drop=True)\n","    return annot_df\n","\n","\n","def upload_file_to_project(filename, proj_dir):\n","    dxpy.upload_local_file(filename, folder=proj_dir, parents=True)\n","    print(f\"*********{filename} uploaded!!*********\")\n","    os.remove(filename)\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vcf_dir = \"/mnt/project/Bulk/Exome sequences/Population level exome OQFE variants, pVCF format - final release/\"\n","chr_num = \"X\"\n","vcf_files = sorted([\"file://\" + os.path.join(vcf_dir, fp) for fp in os.listdir(vcf_dir) if (f\"_c{chr_num}_\" in fp and fp.endswith(\"vcf.gz\"))])\n","\n","# Annotation configure\n","logging.basicConfig(filename=f\"chr{chr_num}_annot_vep109.log\", level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')\n","\n","i=0\n","\n","# change i to new value if the instance restarts\n","proj_dir = f\"/mnt/project/exome_annot/annot_run/notebooks/chr{chr_num}/annot_tables_vep109/\"\n","\n","if os.path.exists(proj_dir):\n","    existing_files = sorted([fp for fp in os.listdir(proj_dir)], key=lambda x: int(''.join(filter(str.isdigit, x))))\n","    last_file = existing_files[-1]\n","    pattern = re.compile(\"^block_(\\d+).tsv.gz$\")\n","    m = re.match(pattern, last_file)\n","    i = int(m.groups()[0])\n","    \n","while i<len(vcf_files):\n","    time_start = time.time()\n","    \n","    # read the matrix table\n","    db_name = f\"exome_chr{chr_num}\"\n","    db_uri = dxpy.find_one_data_object(name=f\"{db_name}\".lower(), classname=\"database\")['id']\n","    mt_name = f\"block_{i}.mt\"\n","    mt_url = f\"dnax://{db_uri}/{mt_name}\"\n","    mt = hl.read_matrix_table(mt_url)\n","    \n","    try:\n","        # create annot table\n","        annot_df = get_annot_table(mt)\n","        # save annot table to local\n","        annot_df_name = f\"block_{i}.tsv.gz\"\n","        annot_df.to_csv(annot_df_name, sep='\\t')\n","        # upload table to project\n","        proj_dir = f\"/exome_annot/annot_run/notebooks/chr{chr_num}/annot_tables_vep109/\"\n","        upload_file_to_project(annot_df_name, proj_dir)\n","\n","        time_end = time.time()\n","        time_taken = (time_end - time_start)/60\n","        logging.info(f\"Time to annotate block {i}: {time_taken} mins\\n\")\n","\n","        # remove tmp files created by hail to prevent storage issues \n","        tmp_dir = \"/tmp/\"\n","        for file in os.listdir(tmp_dir):\n","            if file.startswith(\"persist_Table\"):\n","                os.remove(os.path.join(tmp_dir, file))\n","                \n","    except Exception as error:\n","        logging.warning(f\"block {i} not annotated due to {error}\\n\")\n","        print(f\"!!!!!!!!block {i} not annotated!!!!!!!!\")\n","        \n","    i+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hl.stop()\n","spark.sparkContext.stop()\n","spark.stop()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
