{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "from scipy.stats import kstest,ttest_ind,fisher_exact\n",
    "from scipy.stats.contingency import odds_ratio\n",
    "from scipy import stats\n",
    "import itertools as it\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams.update({'font.size': 14, 'axes.linewidth': 2, 'xtick.major.width': 1.5, 'xtick.major.size': 7, 'ytick.major.width': 1.5, 'ytick.major.size': 7})\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from functools import reduce\n",
    "from scipy.stats import kstest,ttest_ind\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Each ICD10 diagnosis is stored as a Node object\n",
    "    \"\"\"\n",
    "    def __init__(self, node_id, code, meaning, parent=None, child=None):\n",
    "        self.node = node_id\n",
    "        self.parent = parent\n",
    "        self.child = child\n",
    "        self.code, self.meaning = code, meaning\n",
    "        self.samples = set()\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        if self.child:\n",
    "            self.child.append(child_node)\n",
    "        else:\n",
    "            self.child = [child_node]\n",
    "        return\n",
    "\n",
    "    def add_parent(self, parent_node):\n",
    "        if not self.parent:\n",
    "            self.parent = parent_node\n",
    "        else:\n",
    "            assert self.parent == parent_node\n",
    "        return\n",
    "\n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "\n",
    "    def get_child(self):\n",
    "        return self.child\n",
    "\n",
    "    def get_info(self):\n",
    "        return self.code, self.meaning\n",
    "    \n",
    "    def get_samples(self):\n",
    "        return self.samples\n",
    "    \n",
    "    def get_samples_number(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self, root_node, coding_df):\n",
    "        self.root = root_node\n",
    "        self.node_dict = {self.root.node : self.root}\n",
    "        self.coding_df = coding_df\n",
    "\n",
    "    def update_node_dict(self, node_id, node):\n",
    "        if node_id not in self.node_dict:\n",
    "            self.node_dict[node_id] = node\n",
    "        return\n",
    "\n",
    "    def create_node_from_df_helper(self, node_id):\n",
    "        c, m, ni, pi =  self.coding_df.loc[self.coding_df.node_id==node_id].values[0]\n",
    "        n = Node(ni, c, m)\n",
    "        return n, pi\n",
    "\n",
    "    def create_node_from_df(self, node_id):\n",
    "        if node_id in self.node_dict:\n",
    "            return self.node_dict[node_id]\n",
    "\n",
    "        # creating a node and providing parent information\n",
    "        mn, mnpi = self.create_node_from_df_helper(node_id)\n",
    "        # if parent is not present in the tree\n",
    "        if mnpi not in self.node_dict:\n",
    "            # create the parent node and get its parent\n",
    "            mnp = self.create_node_from_df(mnpi)\n",
    "            # add that parent info to the created node\n",
    "            mn.add_parent(mnp)\n",
    "        else:\n",
    "            mnp = self.node_dict[mnpi]\n",
    "            # add that parent info to the created node\n",
    "            mn.add_parent(mnp)\n",
    "\n",
    "        # update the node dict with the created node\n",
    "        self.update_node_dict(node_id, mn)\n",
    "        # add the created node as a child of the parent node\n",
    "        mnp.add_child(mn)\n",
    "        return mn\n",
    "\n",
    "    def print_node(self, curr_node, node_level, tree_file):\n",
    "        curr_node_info = curr_node.get_info()\n",
    "        if tree_file:\n",
    "            tree_file.write(f\"{'-' * node_level}{curr_node.node}\\t{curr_node_info[1]}\\n\")\n",
    "        else:\n",
    "            print(f\"{'-' * node_level}{curr_node.node}\\t{curr_node_info[1]}\\n\")\n",
    "        return\n",
    "\n",
    "    def print_tree(self, curr_node, tree_file=\"\", node_level=0, max_node_level=2):\n",
    "        if node_level>max_node_level:\n",
    "            return\n",
    "        \n",
    "        if curr_node:\n",
    "            self.print_node(curr_node, node_level, tree_file)\n",
    "\n",
    "            if curr_node.child:\n",
    "                for c in curr_node.child:\n",
    "                    self.print_tree(c, tree_file, node_level+1, max_node_level)\n",
    "        return\n",
    "    \n",
    "    def add_sample_info(self, node_id, samples):\n",
    "        curr_node = self.node_dict[node_id]\n",
    "        curr_node.samples = samples.union(curr_node.samples)\n",
    "        if curr_node.parent:\n",
    "            self.add_sample_info(curr_node.parent.node, samples)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(icd_codes_df, icd_samples_df):\n",
    "    # create tree\n",
    "    # plant the tree\n",
    "    root_pheno = Node(0, \"0\", \"Root Phenotype\")\n",
    "    pheno_tree = Tree(root_pheno, icd_codes_df)\n",
    "    # fill the tree with leaves and branches - takes 6 secs\n",
    "    for ni in icd_codes_df.node_id:\n",
    "        pheno_tree.create_node_from_df(ni)\n",
    "    c2nodeid_dict = dict(zip(icd_codes_df.coding, icd_codes_df.node_id))\n",
    "    # add sample info\n",
    "    for icd_code, samples in tqdm.tqdm(zip(icd_samples_df.index, icd_samples_df.sample_names)):\n",
    "        pheno_tree.add_sample_info(c2nodeid_dict[icd_code], set(samples.split(\"|\")))\n",
    "    return pheno_tree, root_pheno, c2nodeid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_icd_samples_file(icd_raw_dir):\n",
    "    dfs = []\n",
    "    for file in os.scandir(icd_raw_dir):\n",
    "        filepath = os.path.join(icd_raw_dir, file)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dfs.append(df)\n",
    "    icd_samples_df = pd.concat(dfs)\n",
    "    icd_samples_df[\"icd\"] = icd_samples_df.icd.str.split(\"|\")\n",
    "    icd_samples_df = icd_samples_df.explode(\"icd\").groupby(\"icd\").agg(lambda x: \"|\".join(map(str,x)))\n",
    "    return icd_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_raw_dir = \"/data6/deepro/ukb_bmi/0_data_preparation_and_download/icd_codes/data/icd_raw\"\n",
    "icd_codes_file = \"/data6/deepro/ukb_bmi/0_data_preparation_and_download/icd_codes/data/icd_tree/coding19.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_samples_df = create_icd_samples_file(icd_raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_codes_df = pd.read_csv(icd_codes_file, usecols=[\"coding\", \"meaning\", \"node_id\", \"parent_id\"], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12215it [08:48, 23.12it/s]\n"
     ]
    }
   ],
   "source": [
    "pheno_tree, root_pheno, c2nodeid_dict = create_tree(icd_codes_df, icd_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84975/797936401.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_other_samples_df[\"description\"] = \"Non Combo\"\n",
      "/tmp/ipykernel_84975/797936401.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_combo_samples_df[\"description\"] = \"Combo\"\n"
     ]
    }
   ],
   "source": [
    "phenotype_file = \"/data6/deepro/ukb_bmi/0_data_preparation_and_download/phenotype/data/bmi_processed/british/train_cohort_bmi.csv.gz\"\n",
    "cohort_files = [\n",
    "    \"/data6/deepro/ukb_bmi/3_characterization/data/combo_info/british/discovery_combo2.csv\",\n",
    "    \"/data6/deepro/ukb_bmi/3_characterization/data/combo_info/british/discovery_combo3.csv\"\n",
    "]\n",
    "\n",
    "phenotype_df = pd.read_csv(phenotype_file)\n",
    "\n",
    "\n",
    "cohort_df = pd.concat([pd.read_csv(cf) for cf in cohort_files])\n",
    "all_combo_samples = set(\"|\".join(cohort_df.combo_samples.values).split(\"|\"))\n",
    "\n",
    "categorical_cols = [\"genetic_sex\"]\n",
    "numerical_cols = [\"age\"] + [f\"genetic_pca{i}\" for i in range(1, 40)]\n",
    "scaled_numerical_cols = []#[\"bmi_prs\"]\n",
    "\n",
    "def get_scaled_bmi(df, categorical_cols, numerical_cols, scaled_numerical_cols):\n",
    "    # define encoders\n",
    "    en = LabelEncoder()\n",
    "    scaler = StandardScaler()\n",
    "    # select the categorical and numerical columns\n",
    "    # transform the categorical columns to integer values\n",
    "    for cat_col in categorical_cols:\n",
    "        df[cat_col] = en.fit_transform(df[cat_col])\n",
    "    # scale the numerical columns\n",
    "    df[numerical_cols] = scaler.fit_transform(df.loc[:, numerical_cols])\n",
    "    # scale bmi separately\n",
    "    df[\"bmi_scaled\"] = scaler.fit_transform(df.loc[:, [\"bmi\"]])\n",
    "    # Create the target variable (bmi_residuals) using linear regression\n",
    "    X = df.loc[:, categorical_cols + numerical_cols + scaled_numerical_cols]\n",
    "    y = df.loc[:, 'bmi_scaled']\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    # save the residuals for bmi\n",
    "    df['bmi_residuals'] = y - model.predict(X)\n",
    "    return df\n",
    "\n",
    "phenotype_df = get_scaled_bmi(phenotype_df, categorical_cols, numerical_cols, scaled_numerical_cols)\n",
    "phenotype_df[\"bmi_res_decile\"] = pd.qcut(phenotype_df.bmi_residuals, q=10)\n",
    "phenotype_df[\"bmi_res_decile_num\"] = pd.qcut(phenotype_df.bmi_residuals, q=10, labels=False)\n",
    "phenotype_combo_samples_df = phenotype_df.loc[phenotype_df.sample_names.astype(str).isin(list(map(str, all_combo_samples)))]\n",
    "phenotype_other_samples_df = phenotype_df.loc[~phenotype_df.sample_names.astype(str).isin(list(map(str, all_combo_samples)))]\n",
    "\n",
    "phenotype_other_samples_df[\"description\"] = \"Non Combo\"\n",
    "phenotype_combo_samples_df[\"description\"] = \"Combo\"\n",
    "phenotype_samples_df = pd.concat((phenotype_combo_samples_df, phenotype_other_samples_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(combo_samples, noncombo_samples, comorbid_samples, field):\n",
    "    table = [\n",
    "        [len(combo_samples.intersection(comorbid_samples)), len(combo_samples.difference(comorbid_samples))],\n",
    "        [len(noncombo_samples.intersection(comorbid_samples)), len(noncombo_samples.difference(comorbid_samples))]\n",
    "    ]\n",
    "    df = pd.DataFrame(table, columns=[f\"{field}\", f\"No {field}\"], index=[\"Combo\", \"Non Combo\"])\n",
    "    return df\n",
    "\n",
    "  \n",
    "def get_icd_enrich_per_decile(decile_df, save_file):\n",
    "    combo_samples = set(decile_df.loc[decile_df.description==\"Combo\", \"sample_names\"].astype(str).values)\n",
    "    noncombo_samples = set(decile_df.loc[decile_df.description==\"Non Combo\", \"sample_names\"].astype(str).values)\n",
    "\n",
    "    icd_data = []\n",
    "\n",
    "    for icdc in tqdm.tqdm(icd_codes_df.coding.values):\n",
    "        icdc_node = pheno_tree.node_dict[c2nodeid_dict[icdc]]\n",
    "        comorbid_samples = icdc_node.get_samples()\n",
    "        df = get_table(combo_samples, noncombo_samples, comorbid_samples, icdc_node.meaning)\n",
    "        res = fisher_exact(df)\n",
    "        or_study = odds_ratio(df)\n",
    "        cil, cih = or_study.confidence_interval(confidence_level=0.95)\n",
    "        icdc_node_data = (icdc, icdc_node.meaning, df.iloc[0,0], df.iloc[0,1], df.iloc[1,0], df.iloc[1,1], or_study.statistic, res.pvalue, cil, cih)\n",
    "        icd_data.append(icdc_node_data)\n",
    "    \n",
    "    icd_df = pd.DataFrame(icd_data, columns=[\"icd_code\", \"icd_meaning\", \"combo_comorbid\", \"combo_noncomorbid\", \"noncombo_comorbid\", \"noncombo_noncomorbid\", \"odds_ratio\", \"p_value\", \"ci_low\", \"ci_high\"])\n",
    "    icd_df[\"FDR\"] = stats.false_discovery_control(icd_df.p_value)\n",
    "    icd_df.to_csv(save_file, index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_decile = phenotype_samples_df.loc[phenotype_samples_df.bmi_res_decile_num==0]\n",
    "bottom_decile_save_file = \"/data6/deepro/ukb_bmi/3_characterization/data/pilot/icd_enrich_zeroth_decile.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19190/19190 [01:56<00:00, 165.09it/s]\n"
     ]
    }
   ],
   "source": [
    "get_icd_enrich_per_decile(bottom_decile, bottom_decile_save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_decile = phenotype_samples_df.loc[phenotype_samples_df.bmi_res_decile_num==9]\n",
    "top_decile_save_file = \"/data6/deepro/ukb_bmi/3_characterization/data/pilot/icd_enrich_tenth_decile.csv\"\n",
    "\n",
    "other_decile = phenotype_samples_df.loc[phenotype_samples_df.bmi_res_decile_num==8]\n",
    "other_decile_save_file = \"/data6/deepro/ukb_bmi/3_characterization/data/pilot/icd_enrich_ninth_decile.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/19190 [00:00<02:13, 143.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19190/19190 [03:12<00:00, 99.47it/s] \n"
     ]
    }
   ],
   "source": [
    "get_icd_enrich_per_decile(top_decile, top_decile_save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 44/19190 [00:00<02:02, 156.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19190/19190 [02:46<00:00, 115.39it/s]\n"
     ]
    }
   ],
   "source": [
    "get_icd_enrich_per_decile(other_decile, other_decile_save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
